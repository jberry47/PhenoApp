## Calculate correlation
cor(Leinhardt$income,
Leinhardt$infant,
use = 'complete.obs')
## Calculate correlation and request statistical test with p values
cor_result_1 <-
cor.test(Leinhardt$income,Leinhardt$infant)
## print the result
cor_result_1
## explore this result
names(cor_result_1)
str(cor_result_1)
## access the correlation
cor_result_1$estimate
## access the p-value
cor_result_1$p.value
## Calculate Kendall correlation
cor(Leinhardt$income,
Leinhardt$infant,
use = 'complete.obs',
method = 'kendall')
## Calculate correlation and request statistical test with p values
cor_result_2 <-
cor.test(Leinhardt$income,
Leinhardt$infant,
method = 'kendall')
## print the result
cor_result_2
x <- 1:10
y <- -3*x + x**2
plot(x,y)
cor(x,y,method = 'pearson')
cor(x,y,method = 'kendall')
## set seed for reproducibel results (so we all get the same answer from the 'simulated' data!)
set.seed(12)
## Simulate an x variable from the uniform distribution:
x_var <- runif(50,1,20)
## simulate an outcome with positive linear correlation:
y_var1 <-
10 + 5*x_var + rnorm(x_var,mean = 0,sd = 7)
plot(x_var,y_var1)
## simulate an outcome with negative linear correlation:
y_var2 <-
10 + -5*x_var + rnorm(x_var,mean = 0,sd = 7)
plot(x_var,y_var2)
## simulate an outcome with positive non-linear correlation:
y_var3 <-
-3*x_var + 0.4*x_var**2 + rnorm(x_var,mean = 0,sd = 3)
plot(x_var,y_var3)
## simulate an outcome with a curvy relationship:
y_var4 <-
6*scale(x_var)**2 + rnorm(scale(x_var),mean = 0,sd = 1.3)
plot(x_var,y_var4)
#scatterplot for gdp and life expectancy with straight line
ggplot(gapminder,aes(gdpPercap,lifeExp)) +
geom_point()+
geom_smooth(method = 'lm',
se = F)
#scatterplot for gdp and life expectancry with loess line
ggplot(gapminder,aes(gdpPercap,lifeExp)) +
geom_point()+
geom_smooth(method = 'loess',
se = F)
#calculate linear correlation coefficient for income and life expectancy
cor.test(gapminder$gdpPercap,gapminder$lifeExp)
#calculate linear correlation coefficient for income and life expectancy
cor(gapminder$gdpPercap,gapminder$lifeExp)
?cor
#calculate linear correlation coefficient for income and life expectancy
cor(gapminder$gdpPercap,gapminder$lifeExp, use = 'complete.obs')
cor.test(gapminder$gdpPercap,gapminder$lifeExp)
cor(gapminder$gdpPercap,gapminder$lifeExp, use = 'complete.obs', method = 'kendall')
cor.test(gapminder$gdpPercap,gapminder$lifeExp, method = 'kendall')
cor.test(gapminder$gdpPercap,gapminder$lifeExp)
cor.test(gapminder$gdpPercap,gapminder$lifeExp, method = 'kendall')
cor(gapminder$gdpPercap,gapminder$lifeExp, use = 'complete.obs', method = 'kendall')
cor.test(gapminder$gdpPercap,gapminder$lifeExp, method = 'kendall')
## Simulate an x variable from the uniform distribution:
x_var <- runif(50,1,20)
## set seed for reproducibel results (so we all get the same answer from the 'simulated' data!)
set.seed(12)
## Simulate an x variable from the uniform distribution:
x_var <- runif(50,1,20)
## simulate an outcome with positive linear correlation:
y_var1 <-
10 + 5*x_var + rnorm(x_var,mean = 0,sd = 7)
## simulate an outcome with negative linear correlation:
y_var2 <-
10 + -5*x_var + rnorm(x_var,mean = 0,sd = 7)
## simulate an outcome with positive non-linear correlation:
y_var3 <-
-3*x_var + 0.4*x_var**2 + rnorm(x_var,mean = 0,sd = 3)
## simulate an outcome with a curvy relationship:
y_var4 <-
6*scale(x_var)**2 + rnorm(scale(x_var),mean = 0,sd = 1.3)
plot(x_var,y_var1)
plot(x_var,y_var2)
plot(x_var,y_var3)
plot(x_var,y_var4)
## simulate an outcome with positive linear correlation:
y_var1 <-
10 + 5*x_var + rnorm(x_var,mean = 0,sd = 7)
plot(x_var,y_var1)
plot(x_var,y_var2)
plot(x_var,y_var3)
plot(x_var,y_var4)
cor(x_var, y_var1, use = 'complete.obs')
cor(x_var, y_var1, use = 'complete.obs')
cor(x_var, y_var1, use = 'complete.obs', method = 'kendall')
plot(x_var,y_var1)
cor(x_var, y_var2, use = 'complete.obs')
cor(x_var, y_var2, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var3, use = 'complete.obs')
cor(x_var, y_var3, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var4, use = 'complete.obs')
cor(x_var, y_var4, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var1, use = 'complete.obs')
cor(x_var, y_var1, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var2, use = 'complete.obs')
cor(x_var, y_var2, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var3, use = 'complete.obs')
cor(x_var, y_var3, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var4, use = 'complete.obs')
cor(x_var, y_var4, use = 'complete.obs', method = 'kendall')
plot(x_var,y_var3)
cor(x_var, y_var3, use = 'complete.obs')
cor(x_var, y_var3, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var1, use = 'complete.obs')
cor(x_var, y_var1, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var2, use = 'complete.obs')
cor(x_var, y_var2, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var3, use = 'complete.obs')
cor(x_var, y_var3, use = 'complete.obs', method = 'kendall')
cor(x_var, y_var4, use = 'complete.obs')
cor(x_var, y_var4, use = 'complete.obs', method = 'kendall')
head(gapminder)
#fitting null model...
ggplot(gapminder,aes(lifeExp)) +
geom_density(fill='grey',alpha=0.5) +
geom_vline(color='red',
xintercept = mean(gapminder$lifeExp,na.rm=T)) +
geom_vline(color='black',
xintercept = median(gapminder$lifeExp,na.rm=T))
lm(lifeExp~gdpPercap, data=gapminder)
summary(lm(lifeExp~gdpPercap, data=gapminder))
library(dplyr)
gapminder %>%
group_by(gdpPercap) %>%
summarise(mean_lifeExp=mean(lifeExp,na.rm=T))
data("Leinhardt")
mod1 <-
lm(infant~oil,
data=Leinhardt)
summary(mod1)
Leinhardt %>%
group_by(oil) %>%
summarise(mean_infant=mean(infant,na.rm=T))
?lm
summary(lm(lifeExp~gdpPercap, data=gapminder))
ggplot(gapminder, aes(x = lifeExp, y = gdpPercap)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
summary(lm(lifeExp~gdpPercap, data=gapminder))
head(gapminder)
summary(lm(lifeExp~year, data=gapminder))
ggplot(gapminder, aes(x = year, y = lifeExp)) +
geom_point() +
stat_smooth(method = "lm", col = "red")
summary(lm(lifeExp~year, data=gapminder))
summary(lm(lifeExp~gdpPercap, data=gapminder))
summary(lm(lifeExp~year, data=gapminder))
summary(lm(lifeExp~gdpPercap, data=gapminder))
summary(lm(lifeExp~year, data=gapminder))
summary(lm(lifeExp~year, data=gapminder))
log(6)
expr(6)
exp(6)
?log
?expand.model.frame
?exp
log(6)
exp(1.791759)
shiny::runApp('/media/emi/ExtraDrive1/danforth/github_repositories/PhenoApp')
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/PhenoApp')
?seq
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/PhenoApp')
(0, 24, 2)
seq(0, 24, 2)
?scale_x_continuous
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/PhenoApp')
?POSIXct
?strptime
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/PhenoApp')
setwd("/media/emi/ExtraDrive1/Classes/HDS_5310/final")
#setwd("/media/emi/ExtraDrive1/Classes/HDS_5310/final")
library(ggplot2)
#Removing variables with more than 10% missing observations.
train <- read.csv("train.csv", header = T, stringsAsFactors = F)
total.na <- sapply(train, function(i) length(which(is.na(i))))
total.notna <- sapply(train, function(i) length(which(!is.na(i))))
which(total.na / (total.na + total.notna) > 0.1)
train <- train[-c(4, 7, 58, 73, 74, 75)]
sapply(train, function(i) length(which(is.na(i))))
#Replacing these NAs with "none" because it's probably attributed to the houses not having garages/basements. Looks like NA was put in instead of None for the MasVnrType column, so changed that as well.
train$MasVnrType[which(is.na(train$MasVnrType))] <- "None"
#These match up with the houses that don't have masontry veneer, so subbed "None"
train$MasVnrArea[which(is.na(train$MasVnrArea))] <- "None"
train$BsmtQual[which(is.na(train$BsmtQual))] <- "None"
train$BsmtCond[which(is.na(train$BsmtCond))] <- "None"
train$GarageType[which(is.na(train$GarageType))] <- "None"
train$BsmtExposure[which(is.na(train$BsmtExposure))] <- "None"
train$BsmtFinType1[which(is.na(train$BsmtFinType1))] <- "None"
train$BsmtFinType2[which(is.na(train$BsmtFinType2))] <- "None"
train$GarageYrBlt[which(is.na(train$GarageYrBlt))] <- "None"
train$GarageFinish[which(is.na(train$GarageFinish))] <- "None"
train$GarageQual[which(is.na(train$GarageQual))] <- "None"
train$GarageCond[which(is.na(train$GarageCond))] <- "None"
#Replaced these NA with the most commonly used value for the respective column.
table(train$Electrical)
train$Electrical[which(is.na(train$Electrical))] <- "SBrkr"
which(is.na(train))
?graphics::pairs
install.packages("rpg")
install.packages("rgp")
library(rgp)
install.packages("rgp")
install.packages("emoa")
library(rgp)
?rgp
summary(glm$SalePrice ~ glm$LotArea)
summary(glm(train$SalePrice ~ train$LotArea))
summary(lm(train$SalePrice ~ train$LotArea))
summary(lm(train$SalePrice ~ train$OverallCond))
colnames(train)
summary(lm(train$SalePrice ~ train$YrSold))
colnames(train)
summary(lm(train$SalePrice ~ train$GarageCars))
colnames(train)
summary(lm(train$SalePrice ~ train$GarageCars + train$YearBuilt))
colnames(train)
summary(lm(train$SalePrice ~ train$GarageCars + train$PoolArea))
colnames(train)
summary(lm(train$SalePrice ~ train$GarageCars + train$FullBath))
colnames(train)
summary(lm(train$SalePrice ~ train$GarageCars + train$BsmtCond))
colnames(train)
summary(lm(train$SalePrice ~ train$LotShape))
colnames(train)
summary(lm(train$SalePrice ~ train$KitchenQual))
colnames(train)
summary(lm(train$SalePrice ~ train$CentralAir))
colnames(train)
summary(lm(train$SalePrice ~ train$SaleType))
colnames(train)
summary(lm(train$SalePrice ~ train$Functional))
colnames(train)
summary(lm(train$SalePrice ~ train$Electrical))
colnames(train)
summary(lm(train$SalePrice ~ train$Street))
colnames(train)
summary(lm(train$SalePrice ~ train$YearRemodAdd))
colnames(train)
summary(lm(train$SalePrice ~ train$YearBuilt))
colnames(train)
summary(lm(train$SalePrice ~ train$YFireplaces))
summary(lm(train$SalePrice ~ train$Fireplaces))
summary(lm(train$SalePrice ~ train$YFireplaces))
colnames(train)
summary(lm(train$SalePrice ~ train$Neighborhood))
summary(lm(train$SalePrice ~ train$Neighborhood + train$GarageCars))
colnames(train)
summary(lm(train$SalePrice ~ train$Neighborhood))
colnames(train)
summary(lm(train$SalePrice ~ train$OpenPorchSF))
colnames(train)
summary(lm(train$SalePrice ~ train$SaleCondition))
colnames(train)
summary(lm(train$SalePrice ~ train$MiscVal))
colnames(train)
summary(lm(train$SalePrice ~ train$HouseStyle))
colnames(train)
summary(lm(train$SalePrice ~ train$Foundation))
colnames(train)
summary(lm(train$SalePrice ~ train$HalfBath))
colnames(train)
summary(lm(train$SalePrice ~ train$FullBath))
colnames(train)
summary(lm(train$SalePrice ~ train$KitchenQual))
summary(lm(train$SalePrice ~ train$KitchenQual + train$Neighborhood))
colnames(train)
summary(lm(train$SalePrice ~ train$GarageQual))
colnames(train)
summary(lm(train$SalePrice ~ train$GrLivArea))
summary(lm(train$SalePrice ~ train$GarageQual + train$GrLivArea))
summary(lm(train$SalePrice ~ train$Neighborhood + train$GrLivArea))
summary(glm(train$SalePrice ~ train$Neighborhood + train$GrLivArea))
#Initial glance into summary data of function of interest.
summary(glm(SalePrice ~ Neighborhood + GrLivArea, data = train))
rsq::rsq(glm(SalePrice ~ Neighborhood + GrLivArea, data = train))
#Checking linearity of residuals.
plot(glm(SalePrice ~ Neighborhood + GrLivArea, data = train))
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Changing x axis to vizualize without four highest outliers.
#Using log scale doesn't change much here either. The correlation still looks pretty much the same.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4500)
#Again changing the x axis to visualize with less data points
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4000)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = GrLivArea, y = Neighborhood, color = GrLivArea))+
geom_jitter()+
geom_smooth(method = glm)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = neighborhood, y = SalePrice, color = GrLivArea))+
geom_jitter()+
geom_smooth(method = glm)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = Neighborhood, y = SalePrice, color = GrLivArea))+
geom_jitter()+
geom_smooth(method = glm)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = OverallCond))+
geom_jitter()+
geom_smooth(method = glm)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference.
ggplot(train, aes(x = GrLivArea, y = log(SalePrice), color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference, and if anything actually made it look messier.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Changing x axis to vizualize without four highest outliers.
#Using log scale doesn't change much here either. The correlation still looks pretty much the same.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4500)
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference, and if anything actually made it look messier. Using the raw data, you can more easily see the differences in sale price between the houses in the different neighborhoods, as well as the general positive relationship between sale price and living area (sq feet).
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Removing just two outliers seems to change the distribution quite a bit.
#Using log scale doesn't change much here either. The correlation still looks pretty much the same.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4500)
#Removing just two outliers seems to change the distribution of the Edwards neighborhood quite a bit.
#Using log scale doesn't change much here either. The correlation still looks pretty much the same.
ggplot(train, aes(x = GrLivArea, y = log(SalePrice), color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4500)
#Again changing the x axis to visualize with less data points
ggplot(train, aes(x = GrLivArea, y = log(SalePrice), color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4000)
#Again changing the x axis to visualize with less data points
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4000)
#Initial glance into summary data of function of interest.
summary(glm(SalePrice ~ Neighborhood + GrLivArea, data = train))
#Pretty good R-squared.
rsq::rsq(glm(SalePrice ~ Neighborhood + GrLivArea, data = train))
#Visualization of the three variables on scatter plot with glm line.
#For this overall visualization of all points, using a log scale of SalePrice didn't really make a difference, and if anything actually made it look messier. Using the raw data, you can more easily see the differences in sale price between the houses in the different neighborhoods, as well as the general positive relationship between sale price and living area (sq feet).
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Removing just two outliers seems to change the distribution of the Edwards neighborhood quite a bit.
#Using log scale doesn't change much here either. It just consolidates everything in a sort of messy way.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4500)
#Initial glance into summary data of function of interest. Several of the neighborhoods show a significant correlation with SalePrice, as does living area.
summary(glm(SalePrice ~ Neighborhood + GrLivArea, data = train))
#Removing just two outliers seems to change the distribution of the Edwards neighborhood quite a bit.
#Using log scale doesn't change much here either. It just consolidates everything in a sort of messy way.
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4500)
#Again changing the x axis to visualize with less data points
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 3000)
#Again changing the x axis to visualize with less data points
ggplot(train, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)+
xlim(0, 4000)
test <- read.csv("test.csv", header = T, stringsAsFactors = F)
which(is.na(test))
sapply(test, function(i) length(which(is.na(i))))
test$Neighborhood
unique(test$Neighborhood)
test_pred <- test(Neighborhood = test$Neighborhood, GrLivArea = test$GrLivArea)
test_pred <- data.frame(Neighborhood = test$Neighborhood, GrLivArea = test$GrLivArea)
predict(train_glm, test_pred, interval="predict")
train_glm <- glm(SalePrice ~ Neighborhood + GrLivArea, data = train)
predict(train_glm, test_pred, interval="predict")
test_pred$SalePrice <- predict(train_glm, test_pred, interval="predict")
train$SalePrice - test_pred$SalePrice
rsq::rsq(glm(SalePrice ~ Neighborhood + GrLivArea, data = test_pred))
plot(glm(SalePrice ~ Neighborhood + GrLivArea, data = test_pred))
ggplot(test_pred, aes(x = GrLivArea, y = SalePrice, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
predict(train_glm, test_pred, interval="predict")
?predict
test_pred <- data.frame(Neighborhood = test$Neighborhood, GrLivArea = test$GrLivArea, SalePrice = NULL)
test_pred <- data.frame(Neighborhood = test$Neighborhood, GrLivArea = test$GrLivArea, SalePrice = NA)
head(test_pred)
predict(train_glm, test_pred, interval="predict")
head(test_pred)
predict(train_glm, newdata = test_pred, interval="predict")
predict(train_glm, newdata = test_pred$SalePrice, interval="predict")
test_pred
colnames(test_pred)
predict.lm(train_glm, newdata = test_pred, interval="predict")
predict.glm(train_glm, newdata = test_pred, interval="predict")
predict(train_glm, newdata = test_pred, interval="predict")
predict.glm(train_glm, newdata = test_pred, interval="prediction")
x <- rnorm(100, 10)
y <- x + rnorm(100, 5)
d <- data.frame(x = x, y = y)
mod <- lm(y ~ x, data = d)
mod
d2 <- data.frame(x = c(0.3, 0.6, 0.2))
predict(mod, newdata = d2, interval = 'prediction')
predict(train_glm, newdata = test_pred, interval="predict")
predict.lm(train_glm, newdata = test_pred, interval="predict")
rbind(test_pred, predict.lm(train_glm, newdata = test_pred, interval="predict"))
rbind(test_pred, predict.lm(train_glm, newdata = test_pred, interval="predict"))
test_pred$SalePrice <- predict.lm(train_glm, newdata = test_pred, interval="predict")
head(test_pred)
predict(train_glm, newdata = test_pred, interval="predict")
test_pred$SalePrice.pred <- predict(train_glm, newdata = test_pred, interval="predict")
head(test_pred)
#Residuals look a tad bit wonky.
plot(glm(SalePrice ~ Neighborhood + GrLivArea, data = test_pred))
glm(SalePrice ~ Neighborhood + GrLivArea, data = test_pred)
#Residuals look a tad bit wonky.
plot(glm(SalePrice.pred ~ Neighborhood + GrLivArea, data = test_pred))
#The model predicted very linear relationships between the variables. Edwards is a little bit crazy probably because of those two outliers from the previous data.
ggplot(test_pred, aes(x = GrLivArea, y = SalePrice.pred, color = Neighborhood))+
geom_jitter()+
geom_smooth(method = glm)
#Pretty good R-squared.
rsq::rsq(glm(log(SalePrice) ~ Neighborhood + GrLivArea, data = train))
shiny::runApp('/media/emi/ExtraDrive1/danforth/shinyApps/cas_xam_2014')
runApp('/media/emi/ExtraDrive1/danforth/shinyApps/cas_xam_2014')
shiny::runApp('Documents/cassava_atlas/Shiny-Cassava')
runApp('Documents/cassava_atlas/Shiny-Cassava')
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-cassava_atlas')
runApp('Documents/cassava_atlas/Shiny-Cassava')
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-PhenoAnalyzer')
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-16S')
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-PhenoAnalyzer')
load("/media/emi/ExtraDrive1/danforth/pheno_stuff/pheno2/pheno2_b_counts.RData")
head(pheno2_b_counts)
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-PhenoAnalyzer')
load("/media/emi/ExtraDrive1/danforth/pheno_stuff/pheno2/pheno2_b_counts.RData")
y <- pheno2_b_counts[,str_detect(colnames(pheno2_b_counts),"OTU")]
x <- pheno2_b_counts[,c("Nitrogen","Geno","Microbes")]
head(pheno2_b_counts)
x <- pheno2_b_counts[,c("Genotype","Treatment","Microbes")]
head(y)
head(x)
?capscale
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-PhenoAnalyzer')
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-PhenoAnalyzer')
runApp('/media/emi/ExtraDrive1/danforth/github_repositories/Shiny-PhenoAnalyzer')
shiny::runApp()
shiny::runApp()
runApp()
shiny::runApp()
